**یادگیری نیمه‌نظارتی ثابت کرده است که پارادایمی قدرتمند برای استفاده از داده‌های بدون برچسب برای کاهش وابستگی به مجموعه‌داده‌های برچسب‌دار بزرگ است. در این کار، ما رویکردهای غالب فعلی برای یادگیری نیمه‌نظارتی را متحد می‌کنیم تا الگوریتم جدیدی به نام MixMatch تولید کنیم که برچسب‌های کم-آنتروپی را برای نمونه‌های بدون برچسب تقویت‌شده با داده حدس می‌زند و داده‌های برچسب‌دار و بدون برچسب را با استفاده از MixUp ترکیب می‌کند. MixMatch با حاشیه قابل توجهی در بسیاری از مجموعه‌داده‌ها و مقادیر داده‌های برچسب‌دار، نتایج پیشرفته‌ای را به دست می‌آورد. برای مثال، در CIFAR-10 با 250 برچسب، نرخ خطا را به میزان 4 برابر (از 38% به 11%) کاهش می‌دهیم و در STL-10 به میزان 2 برابر کاهش می‌دهیم. همچنین نشان می‌دهیم که چگونه MixMatch می‌تواند به دستیابی به توازن دقت-حریم خصوصی بسیار بهتر برای حریم خصوصی دیفرانسیلی کمک کند. در نهایت، یک مطالعه ابلیشن انجام می‌دهیم تا مشخص کنیم کدام اجزای MixMatch برای موفقیت آن مهم‌ترین هستند. ما تمام کد مورد استفاده در آزمایش‌های خود را منتشر می‌کنیم.**

**1. مقدمه**

بخش زیادی از موفقیت‌های اخیر در آموزش شبکه‌های عصبی عمیق بزرگ تا حدی به دلیل وجود مجموعه‌داده‌های برچسب‌دار بزرگ است. با این حال، جمع‌آوری داده‌های برچسب‌دار برای بسیاری از وظایف یادگیری پرهزینه است زیرا لزوماً دانش تخصصی را در بر می‌گیرد. این موضوع شاید به بهترین شکل توسط وظایف پزشکی نشان داده شود، جایی که اندازه‌گیری‌ها نیازمند ماشین‌آلات گران‌قیمت هستند و برچسب‌ها حاصل تحلیل زمان‌بر هستند که از چندین متخصص انسانی استفاده می‌کند. علاوه بر این، برچسب‌های داده ممکن است حاوی اطلاعات خصوصی باشند. در مقایسه، در بسیاری از وظایف، به دست آوردن داده‌های بدون برچسب بسیار آسان‌تر یا ارزان‌تر است. یادگیری نیمه‌نظارتی [6] (SSL) به دنبال کاهش قابل توجه نیاز به داده‌های برچسب‌دار با اجازه دادن به یک مدل برای استفاده از داده‌های بدون برچسب است. بسیاری از رویکردهای اخیر برای یادگیری نیمه‌نظارتی یک عبارت ضرر را اضافه می‌کنند که بر روی داده‌های بدون برچسب محاسبه می‌شود و مدل را تشویق می‌کند تا به داده‌های دیده نشده بهتر تعمیم دهد. در بسیاری از کارهای اخیر، این عبارت ضرر در یکی از سه کلاس قرار می‌گیرد (که در بخش 2 بیشتر مورد بحث قرار می‌گیرد): کمینه‌سازی آنتروپی [18، 28]—که مدل را تشویق می‌کند تا پیش‌بینی‌های مطمئن را بر روی داده‌های بدون برچسب خروجی دهد؛ Consistency Regularization—که مدل را تشویق می‌کند تا هنگام تغییر ورودی‌هایش، توزیع خروجی یکسانی تولید کند؛ و منظم‌سازی عمومی—که مدل را تشویق می‌کند تا به خوبی تعمیم دهد و از بیش‌برازش داده‌های آموزشی جلوگیری کند. در این مقاله، ما MixMatch را معرفی می‌کنیم، یک الگوریتم SSL که یک ضرر واحد را معرفی می‌کند که به طور ظریف این رویکردهای غالب به یادگیری نیمه‌نظارتی را متحد می‌کند. برخلاف روش‌های قبلی، MixMatch تمام ویژگی‌ها را به طور همزمان هدف قرار می‌دهد که به نظر ما منجر به مزایای زیر می‌شود:

![[./assets/c1.png]](/assets/c1.png)


**شکل 1:** نمودار فرآیند حدس زدن برچسب مورد استفاده در MixMatch. تقویت داده تصادفی K بار بر روی یک تصویر بدون برچسب اعمال می‌شود و هر تصویر تقویت‌شده از طریق طبقه‌بندی‌کننده تغذیه می‌شود. سپس، میانگین این K پیش‌بینی با تنظیم دمای توزیع، "sharp" می‌شود. برای توضیحات کامل، به الگوریتم 1 مراجعه کنید.

- به طور تجربی، نشان می‌دهیم که MixMatch در تمام بنچمارک‌های استاندارد تصویر نتایج پیشرفته‌ای را به دست می‌آورد (بخش 4.2) و نرخ خطا را در CIFAR-10 به میزان 4 برابر کاهش می‌دهد.
- همچنین در یک مطالعه ابلیشن نشان می‌دهیم که MixMatch بیشتر از مجموع اجزای آن است.
- در بخش 4.3 نشان می‌دهیم که MixMatch برای یادگیری حریم خصوصی دیفرانسیلی مفید است و دانش‌آموزان را در چارچوب PATE [36] قادر می‌سازد تا نتایج پیشرفته جدیدی را به دست آورند که به طور همزمان ضمانت‌های حریم خصوصی و دقت را تقویت می‌کند.

به طور خلاصه، MixMatch یک عبارت ضرر متحد برای داده‌های بدون برچسب معرفی می‌کند که به طور یکپارچه آنتروپی را کاهش می‌دهد، در حالی که سازگاری را حفظ می‌کند و با تکنیک‌های منظم‌سازی سنتی سازگار باقی می‌ماند.


**کارهای مرتبط**

برای آماده‌سازی زمینه برای MixMatch، ابتدا روش‌های موجود برای SSL را معرفی می‌کنیم. ما عمدتاً بر روش‌هایی تمرکز می‌کنیم که در حال حاضر پیشرفته هستند و MixMatch بر پایه آن‌ها ساخته شده است؛ ادبیات گسترده‌ای در مورد تکنیک‌های SSL وجود دارد که در اینجا به آن‌ها نمی‌پردازیم (به عنوان مثال، مدل‌های "انتقالی" [14، 22، 21]، روش‌های مبتنی بر گراف [49، 4، 29]، مدل‌سازی مولد [3، 27، 41، 9، 17، 23، 38، 34، 42] و غیره). بررسی‌های جامع‌تری در [49، 6] ارائه شده است. در ادامه، به یک مدل عمومی pmodel(y | x; θ) اشاره خواهیم کرد که برای یک ورودی x با پارامترهای θ، توزیعی بر روی برچسب‌های کلاس y تولید می‌کند.

**2.1 Consistency Regularizationarization**

یک تکنیک منظم‌سازی رایج در یادگیری نظارت‌شده، تقویت داده است که تبدیل‌های ورودی را اعمال می‌کند که فرض می‌شود معنای کلاس را بدون تغییر باقی می‌گذارند. به عنوان مثال، در طبقه‌بندی تصویر، معمول است که تصویر ورودی را به صورت الاستیک تغییر شکل دهیم یا نویز به آن اضافه کنیم، که می‌تواند محتوای پیکسل یک تصویر را بدون تغییر برچسب آن به طور چشمگیری تغییر دهد [7، 43، 10]. به طور کلی، این می‌تواند به طور مصنوعی اندازه مجموعه آموزشی را با تولید یک جریان تقریباً بی‌نهایت از داده‌های جدید و اصلاح‌شده گسترش دهد. Consistency Regularization، تقویت داده را با استفاده از این ایده که یک طبقه‌بندی‌کننده باید توزیع کلاس یکسانی را برای یک نمونه بدون برچسب حتی پس از تقویت آن خروجی دهد، به یادگیری نیمه‌نظارتی اعمال می‌کند. به طور رسمی‌تر، Consistency Regularization اعمال می‌کند که یک نمونه بدون برچسب x باید همانند Augment(x)، یک تقویت از خودش، طبقه‌بندی شود. در ساده‌ترین حالت، برای نقاط بدون برچسب x، کارهای قبلی [25، 40] عبارت ضرر زیر را اضافه می‌کنند:

![[assets/c2.png]](/assets/c2.png)

```
||pmodel(y | x; θ) - pmodel(y | Augment(x); θ)||^2
```

توجه داشته باشید که Augment(x) یک تبدیل تصادفی (stochastic transformation) است، بنابراین دو عبارت در معادله (1) یکسان نیستند. "معلم میانگین" [44] یکی از عبارات در معادله (1) را با خروجی مدل با استفاده از میانگین متحرک نمایی مقادیر پارامتر مدل جایگزین می‌کند. این یک هدف پایدارتر فراهم می‌کند و به طور تجربی مشخص شد که نتایج را به طور قابل توجهی بهبود می‌بخشد. یک نقطه ضعف این رویکردها این است که از استراتژی‌های تقویت داده خاص دامنه استفاده می‌کنند. "آموزش خصمانه مجازی" [31] (VAT) با محاسبه یک اختلال افزودنی برای اعمال به ورودی که حداکثر توزیع کلاس خروجی را تغییر می‌دهد، به این موضوع می‌پردازد. MixMatch از طریق استفاده از تقویت داده استاندارد برای تصاویر (چرخش‌ها و برش‌های افقی تصادفی) از نوعی Consistency Regularization استفاده می‌کند.


## کمینه‌سازی آنتروپی

یک فرض اساسی رایج در بسیاری از روش‌های یادگیری نیمه‌نظارتی این است که مرز تصمیم طبقه‌بندی‌کننده نباید از مناطق با چگالی بالا توزیع داده‌های حاشیه‌ای عبور کند. یک راه برای اعمال این موضوع، الزام طبقه‌بندی‌کننده به خروجی پیش‌بینی‌های کم-آنتروپی بر روی داده‌های بدون برچسب است. این کار به طور صریح در [18] با یک عبارت ضرر انجام می‌شود که آنتروپی pmodel(y | x; θ) را برای داده‌های بدون برچسب x کمینه می‌کند. این نوع کمینه‌سازی آنتروپی در [31] با VAT ترکیب شد تا نتایج قوی‌تری به دست آید. "برچسب شبه" [28] کمینه‌سازی آنتروپی را به طور ضمنی با ساخت برچسب‌های سخت (1-hot) از پیش‌بینی‌های با اطمینان بالا بر روی داده‌های بدون برچسب و استفاده از آن‌ها به عنوان اهداف آموزشی در یک ضرر آنتروپی متقابل استاندارد انجام می‌دهد. MixMatch همچنین به طور ضمنی از طریق استفاده از یک تابع "تیز کردن" بر روی توزیع هدف برای داده‌های بدون برچسب، که در بخش 3.2 توضیح داده شده است، به کمینه‌سازی آنتروپی دست می‌یابد.

### منظم‌سازی سنتی

منظم‌سازی به رویکرد کلی تحمیل یک محدودیت بر یک مدل اشاره دارد تا حفظ داده‌های آموزشی را دشوارتر کند و بنابراین امیدواریم که تعمیم بهتری به داده‌های دیده نشده داشته باشد [19]. ما از کاهش وزن استفاده می‌کنیم که نرم L2 پارامترهای مدل را جریمه می‌کند [30، 46]. ما همچنین از MixUp [47] در MixMatch استفاده می‌کنیم تا رفتار محدب را "بین" نمونه‌ها تشویق کنیم. ما از MixUp هم به عنوان یک منظم‌کننده (اعمال شده به نقاط داده برچسب‌دار) و هم به عنوان یک روش یادگیری نیمه‌نظارتی (اعمال شده به نقاط داده بدون برچسب) استفاده می‌کنیم. MixUp قبلاً برای یادگیری نیمه‌نظارتی اعمال شده است؛ به ویژه، کار همزمان [45] از زیرمجموعه‌ای از روش‌شناسی مورد استفاده در MixMatch استفاده می‌کند. ما تفاوت‌ها را در مطالعه ابلیشن خود (بخش 4.2.3) روشن می‌کنیم.

### MixMatch

در این بخش، MixMatch، روش یادگیری نیمه‌نظارتی پیشنهادی خود را معرفی می‌کنیم. MixMatch یک رویکرد "جامع" است که ایده‌ها و اجزای پارادایم‌های غالب برای SSL که در بخش 2 مورد بحث قرار گرفت را در خود جای می‌دهد. با توجه به یک دسته X از نمونه‌های برچسب‌دار با اهداف 1-hot (نشان‌دهنده یکی از L برچسب ممکن) و یک دسته U با اندازه مساوی از نمونه‌های بدون برچسب، MixMatch یک دسته پردازش‌شده از نمونه‌های برچسب‌دار تقویت‌شده X 0 و یک دسته از نمونه‌های بدون برچسب تقویت‌شده با برچسب‌های "حدس زده شده" U 0 تولید می‌کند. U 0 و X 0 سپس در محاسبه عبارات ضرر جداگانه برچسب‌دار و بدون برچسب استفاده می‌شوند. به طور رسمی‌تر، ضرر ترکیبی L برای یادگیری نیمه‌نظارتی به صورت زیر تعریف می‌شود:
![[assets/c4.png]](/assets/c4.png)
```
L = L_X + λ_U * L_U
```

که در آن H(p, q) آنتروپی متقابل بین توزیع‌های p و q است و T، K، α و λU ابرپارامترهایی هستند که در زیر توضیح داده می‌شوند. الگوریتم کامل MixMatch در الگوریتم 1 ارائه شده است و نمودار فرآیند حدس زدن برچسب در شکل 1 نشان داده شده است. در ادامه، هر بخش از MixMatch را توضیح می‌دهیم.


#### 3.1 تقویت داده

همانطور که در بسیاری از روش‌های SSL معمول است، ما از تقویت داده هم بر روی داده‌های برچسب‌دار و هم بدون برچسب استفاده می‌کنیم. برای هر xb در دسته داده‌های برچسب‌دار X، یک نسخه تبدیل شده xˆb = Augment(xb) تولید می‌کنیم (الگوریتم 1، خط 3). برای هر ub در دسته داده‌های بدون برچسب U، K تقویت uˆb,k = Augment(ub)، k ∈ (1، ...، K) تولید می‌کنیم (الگوریتم 1، خط 5). ما از این تقویت‌های جداگانه برای تولید یک "برچسب حدس زده شده" qb برای هر ub، از طریق فرآیندی که در زیربخش بعدی توضیح می‌دهیم، استفاده می‌کنیم.

#### 3.2 حدس زدن برچسب

برای هر نمونه بدون برچسب در U، MixMatch با استفاده از پیش‌بینی‌های مدل، یک "حدس" برای برچسب نمونه تولید می‌کند. این حدس بعداً در عبارت ضرر بدون نظارت استفاده می‌شود. برای انجام این کار، میانگین توزیع‌های کلاس پیش‌بینی‌شده مدل را در تمام K تقویت ub با استفاده از

![[assets/c5.png]](/assets/c5.png)

```
q¯b = 1/K * Σ(pmodel(y | uˆb,k; θ))
```

در الگوریتم 1، خط 7، محاسبه می‌کنیم. استفاده از تقویت داده برای به دست آوردن یک هدف مصنوعی برای یک نمونه بدون برچسب در روش‌های Consistency Regularization رایج است [25، 40، 44]. تیز کردن U 0. 

![[assets/c15.png]](/assets/c15.png)

در تولید یک حدس برچسب، یک مرحله اضافی را با الهام از موفقیت کمینه‌سازی آنتروپی در یادگیری نیمه‌نظارتی (که در بخش 2.2 مورد بحث قرار گرفت) انجام می‌دهیم. با توجه به میانگین پیش‌بینی در تقویت‌ها q¯b، یک تابع تیز کردن را برای کاهش آنتروپی توزیع برچسب اعمال می‌کنیم. در عمل، برای تابع تیز کردن، از رویکرد رایج تنظیم "دما" این توزیع دسته‌بندی استفاده می‌کنیم [16]، که به عنوان عملیات زیر تعریف می‌شود:

![[assets/c8.png]](/assets/c8.png)

```
Sharpen(p, T)_i = p_i^(1/T) / Σ(p_j^(1/T))
```

(7)

که p یک توزیع دسته‌بندی ورودی است (به طور خاص در MixMatch، p میانگین پیش‌بینی کلاس در تقویت‌ها q¯b است، همانطور که در الگوریتم 1، خط 8 نشان داده شده است) و T یک ابرپارامتر است. با نزدیک شدن T به 0، خروجی Sharpen(p, T) به یک توزیع دیراک ("1-hot") نزدیک می‌شود. از آنجایی که بعداً از qb = Sharpen(¯qb, T) به عنوان یک هدف برای پیش‌بینی مدل برای یک تقویت ub استفاده خواهیم کرد، کاهش دما مدل را تشویق می‌کند تا پیش‌بینی‌های کم-آنتروپی تولید کند.

### MixUp

ما از MixUp برای یادگیری نیمه‌نظارتی استفاده می‌کنیم و برخلاف کارهای گذشته برای SSL، هم نمونه‌های برچسب‌دار و هم نمونه‌های بدون برچسب را با حدس‌های برچسب (که همانطور که در بخش 3.2 توضیح داده شد تولید می‌شوند) ترکیب می‌کنیم. برای سازگاری با عبارات ضرر جداگانه خود، یک نسخه کمی اصلاح شده از MixUp را تعریف می‌کنیم. برای یک جفت از دو نمونه با احتمالات برچسب مربوطه (x1; p1)؛ (x2; p2)، (x0; p0) را با استفاده از


![[assets/c9.png]](/assets/c9.png)

```
λ = Beta(α, α)
λ0 = max(λ, 1-λ)
x0 = λ0x1 + (1-λ0)x2
p0 = λ0p1 + (1-λ0)p2
```

محاسبه می‌کنیم.

که α یک ابرپارامتر است. MixUp وانیلی معادله (9) را حذف می‌کند (یعنی λ0 = λ را تنظیم می‌کند). با توجه به اینکه نمونه‌های برچسب‌دار و بدون برچسب در یک دسته یکسان به هم متصل می‌شوند، باید ترتیب دسته را برای محاسبه اجزای ضرر جداگانه به درستی حفظ کنیم. این کار با معادله (9) انجام می‌شود که تضمین می‌کند x0 به x1 نزدیک‌تر از x2 است. برای اعمال MixUp، ابتدا تمام نمونه‌های برچسب‌دار تقویت‌شده را با برچسب‌هایشان و تمام نمونه‌های بدون برچسب را با حدس‌های برچسبشان در


![[assets/c10.png]](/assets/c10.png)

```
X^ = [(xˆb; yb)]
U^ = [(uˆb,1; qb)]
```

جمع‌آوری می‌کنیم (الگوریتم 1، خطوط 10-11). سپس، این مجموعه‌ها را ترکیب می‌کنیم و نتیجه را به هم می‌زنیم تا W را تشکیل دهیم که به عنوان منبع داده برای MixUp عمل می‌کند (الگوریتم 1، خط 12). برای هر جفت نمونه-برچسب i ام در X^، MixUp(X^i; Wi) را محاسبه می‌کنیم و نتیجه را به مجموعه X0 اضافه می‌کنیم (الگوریتم 1، خط 13). Ui0 = MixUp(U^i; Wi+jXj ^ ) را برای i ∈ (1، ...، jUj ^ ) محاسبه می‌کنیم، عمداً از بقیه W که در ساخت X0 استفاده نشده است استفاده می‌کنیم (الگوریتم 1، خط 14). به طور خلاصه، MixMatch X را به X0 تبدیل می‌کند، مجموعه‌ای از نمونه‌های برچسب‌دار که تقویت داده و MixUp (به طور بالقوه با یک نمونه بدون برچسب ترکیب شده) روی آنها اعمال شده است. به طور مشابه، U به U0 تبدیل می‌شود، مجموعه‌ای از تقویت‌های متعدد هر نمونه بدون برچسب با حدس‌های برچسب مربوطه.

#### تابع ضرر

با توجه به دسته‌های پردازش‌شده X0 و U0، ما از ضرر نیمه‌نظارتی استاندارد نشان داده شده در معادلات (3) تا (5) استفاده می‌کنیم. معادله (5) ضرر آنتروپی متقابل معمولی بین برچسب‌ها و پیش‌بینی‌های مدل از X0 را با ضرر L2 مربع شده بر روی پیش‌بینی‌ها و برچسب‌های حدس زده شده از U0 ترکیب می‌کند. ما از این ضرر L2 در معادله (4) (امتیاز Brier چند کلاسه [5]) استفاده می‌کنیم زیرا، برخلاف آنتروپی متقابل، محدود است و به پیش‌بینی‌های نادرست حساسیت کمتری دارد. به همین دلیل، اغلب به عنوان ضرر داده‌های بدون برچسب در SSL [25، 44] و همچنین معیاری برای عدم قطعیت پیش‌بینی [26] استفاده می‌شود. ما گرادیان‌ها را از طریق محاسبه برچسب‌های حدس زده شده منتشر نمی‌کنیم، همانطور که استاندارد است [25، 44، 31، 35].

#### ابرپارامترها

از آنجایی که MixMatch مکانیسم‌های متعددی را برای استفاده از داده‌های بدون برچسب ترکیب می‌کند، ابرپارامترهای مختلفی را معرفی می‌کند - به طور خاص، دمای تیز کردن T، تعداد تقویت‌های بدون برچسب K، پارامتر α برای بتا در MixUp، و وزن ضرر بدون نظارت λU. در عمل، روش‌های یادگیری نیمه‌نظارتی با ابرپارامترهای زیاد می‌تواند مشکل‌ساز باشد زیرا اعتبارسنجی متقابل با مجموعه‌های اعتبارسنجی کوچک دشوار است [35، 39، 35]. با این حال، در عمل متوجه می‌شویم که بیشتر ابرپارامترهای MixMatch را می‌توان ثابت کرد و نیازی به تنظیم بر اساس هر آزمایش یا هر مجموعه داده نیست. به طور خاص، برای همه آزمایش‌ها T = 0.5 و K = 2 را تنظیم می‌کنیم. علاوه بر این، ما فقط α و λU را بر اساس هر مجموعه داده تغییر می‌دهیم؛ متوجه شدیم که α = 0.75 و λU = 100 نقاط شروع خوبی برای تنظیم هستند. در همه آزمایش‌ها، همانطور که معمول است [44]، λU را به طور خطی در 16000 مرحله اول آموزش به حداکثر مقدار خود می‌رسانیم.

## آزمایش‌ها

ما اثربخشی MixMatch را در بنچمارک‌های استاندارد SSL آزمایش می‌کنیم (بخش 4.2). مطالعه ابلیشن ما سهم هر یک از اجزای MixMatch را جدا می‌کند (بخش 4.2.3). به عنوان یک کاربرد اضافی، یادگیری حفظ حریم خصوصی را در بخش 4.3 در نظر می‌گیریم.

### جزئیات پیاده‌سازی

مگر اینکه خلاف آن ذکر شده باشد، در همه آزمایش‌ها از مدل "Wide ResNet-28" از [35] استفاده می‌کنیم. پیاده‌سازی مدل و روش آموزشی ما به طور دقیق با [35] مطابقت دارد (از جمله استفاده از 5000 نمونه برای انتخاب ابرپارامترها)، به جز تفاوت‌های زیر: اول، به جای کاهش نرخ یادگیری، مدل‌ها را با استفاده از میانگین متحرک نمایی پارامترهایشان با نرخ کاهش 0.999 ارزیابی می‌کنیم. دوم، در هر به‌روزرسانی برای مدل Wide ResNet-28، کاهش وزن 0.0004 اعمال می‌کنیم. در نهایت، هر 216 نمونه آموزشی را چک‌پوینت می‌کنیم و میانگین نرخ خطای 20 چک‌پوینت آخر را گزارش می‌دهیم. این کار تحلیل را با هزینه احتمالی دقت ساده می‌کند، به عنوان مثال، با میانگین‌گیری چک‌پوینت‌ها [2] یا انتخاب چک‌پوینت با کمترین خطای اعتبارسنجی.

### یادگیری نیمه‌نظارتی

ابتدا، اثربخشی MixMatch را بر روی چهار مجموعه داده معیار استاندارد ارزیابی می‌کنیم: CIFAR-10 و CIFAR-100 [24]، SVHN [32] و STL-10 [8]. روش استاندارد برای ارزیابی یادگیری نیمه‌نظارتی بر روی سه مجموعه داده اول، رفتار کردن با بیشتر مجموعه داده به عنوان بدون برچسب و استفاده از بخش کوچکی به عنوان داده برچسب‌دار است. STL-10 یک مجموعه داده است که به طور خاص برای SSL طراحی شده است، با 5000 تصویر برچسب‌دار و 100000 تصویر بدون برچسب که از توزیع کمی متفاوت از داده‌های برچسب‌دار گرفته شده‌اند.

![[assets/C11.png]](/assets/C11.png)

**شکل 2:** مقایسه نرخ خطای MixMatch با روش‌های پایه در CIFAR-10 برای تعداد متغیر برچسب‌ها. اعداد دقیق در جدول 5 (پیوست) ارائه شده است. "نظارت شده" به آموزش با تمام 50000 نمونه آموزشی و بدون داده‌های بدون برچسب اشاره دارد. با 250 برچسب، MixMatch به نرخ خطایی قابل مقایسه با عملکرد بهترین روش بعدی با 4000 برچسب می‌رسد.

**شکل 3:** مقایسه نرخ خطای MixMatch با روش‌های پایه در SVHN برای تعداد متغیر برچسب‌ها. اعداد دقیق در جدول 6 (پیوست) ارائه شده است. "نظارت شده" به آموزش با تمام 73257 نمونه آموزشی و بدون داده‌های بدون برچسب اشاره دارد. با 250 نمونه، MixMatch تقریباً به دقت آموزش نظارت شده برای این مدل می‌رسد.

### روش‌های پایه

به عنوان خطوط پایه، چهار روش در نظر گرفته شده در [35] را در نظر می‌گیریم (Π-Model [25، 40]، معلم میانگین [44]، آموزش خصمانه مجازی [31] و برچسب شبه [28]) که در بخش 2 توضیح داده شده‌اند. ما همچنین از MixUp [47] به تنهایی به عنوان یک خط پایه استفاده می‌کنیم. MixUp به عنوان یک منظم‌کننده برای یادگیری نظارت شده طراحی شده است، بنابراین ما آن را برای SSL با اعمال آن هم به نمونه‌های برچسب‌دار تقویت‌شده و هم به نمونه‌های بدون برچسب تقویت‌شده با پیش‌بینی‌های مربوطه‌شان اصلاح می‌کنیم. مطابق با استفاده استاندارد از MixUp، از یک ضرر آنتروپی متقابل بین برچسب حدس زده شده تولید شده توسط MixUp و پیش‌بینی مدل استفاده می‌کنیم. همانطور که توسط [35] توصیه شده است، ما هر یک از این روش‌ها را در همان پایگاه کد پیاده‌سازی کردیم و آنها را به همان مدل اعمال کردیم (که در بخش 4.1 توضیح داده شد) تا از مقایسه منصفانه اطمینان حاصل کنیم. ما ابرپارامترها را برای هر روش پایه دوباره تنظیم کردیم، که به طور کلی منجر به بهبود حاشیه‌ای دقت در مقایسه با موارد موجود در [35] شد، در نتیجه یک محیط آزمایشی رقابتی‌تر برای آزمایش MixMatch فراهم کرد.

#### نتایج

‏**CIFAR-10** برای CIFAR-10، دقت هر روش را با تعداد متغیر نمونه‌های برچسب‌دار از 250 تا 4000 ارزیابی می‌کنیم (همانطور که روش استاندارد است). نتایج را می‌توان در شکل 2 مشاهده کرد. ما از λU = 75 برای CIFAR-10 استفاده کردیم. ما 5 تقسیم برای هر تعداد نقطه برچسب‌دار ایجاد کردیم که هر کدام دارای یک دانه تصادفی متفاوت بودند. هر مدل بر روی هر تقسیم آموزش داده شد و نرخ‌های خطا توسط میانگین و واریانس در بین تقسیم‌ها گزارش شدند. ما متوجه شدیم که MixMatch با حاشیه قابل توجهی از همه روش‌های دیگر بهتر عمل می‌کند، برای مثال با 4000 برچسب به نرخ خطای 6.24 درصد می‌رسد. برای مرجع، در همان مدل، آموزش کاملاً نظارت شده بر روی تمام 50000 نمونه به نرخ خطای 4.17 درصد می‌رسد. علاوه بر این، MixMatch با تنها 250 برچسب به نرخ خطای 11.08 درصد می‌رسد. برای مقایسه، در 250 برچسب، بهترین روش بعدی (VAT [31]) به نرخ خطای 36.03 می‌رسد، بیش از 4.5 برابر بیشتر از MixMatch با توجه به اینکه 4.17 درصد حد خطای به دست آمده در مدل ما با یادگیری کاملاً نظارت شده است. علاوه بر این، در 4000 برچسب، بهترین روش بعدی (معلم میانگین [44]) به نرخ خطای 10.36 درصد می‌رسد، که نشان می‌دهد MixMatch می‌تواند با تنها 1/16 برچسب مشابه عملکرد را به دست آورد. ما معتقدیم که جالب‌ترین مقایسه‌ها با تعداد بسیار کمی از نقاط داده برچسب‌دار هستند، زیرا کارایی نمونه روش را نشان می‌دهد که برای SSL مرکزی است.

‏**CIFAR-10 و CIFAR-100 با یک مدل بزرگتر** برخی از کارهای قبلی [44، 2] استفاده از یک مدل بزرگتر با 26 میلیون پارامتر را نیز در نظر گرفته‌اند. مدل پایه ما، همانطور که در [35] استفاده شده است، تنها 1.5 میلیون پارامتر دارد که مقایسه با این نتایج را دشوار می‌کند. برای مقایسه منطقی‌تر با این نتایج، اثر افزایش عرض مدل ResNet پایه خود را اندازه‌گیری می‌کنیم و عملکرد MixMatch را بر روی یک مدل Wide Resnet 28 لایه که 135 فیلتر در هر لایه دارد، که منجر به 26 میلیون پارامتر می‌شود، ارزیابی می‌کنیم. ما همچنین MixMatch را بر روی این مدل بزرگتر در CIFAR-100 با 10000 برچسب ارزیابی می‌کنیم تا با نتیجه مربوطه از [2] مقایسه کنیم. نتایج در جدول 1 نشان داده شده است. به طور کلی، MixMatch با بهترین نتایج از [2] مطابقت دارد یا بهتر از آن عمل می‌کند، اگرچه توجه داریم که مقایسه همچنان به دلیل این واقعیت که مدل از [44، 2] نیز از منظم‌سازی "shake-shake" پیچیده‌تر [15] استفاده می‌کند، مشکل‌ساز باقی می‌ماند. برای این مدل، از کاهش وزن 0.0008 استفاده کردیم. از λU = 75 برای CIFAR-10 و λU = 150 برای CIFAR-100 استفاده کردیم.


![[assets/c12.png]](/assets/c12.png)

**جدول 3:** مقایسه نرخ‌های خطا برای SVHN و SVHN+Extra برای MixMatch. ستون آخر ("همه") شامل عملکرد کاملاً نظارت شده با تمام برچسب‌ها در مجموعه آموزشی مربوطه است.


‏**SVHN و SVHN+Extra** مانند CIFAR-10، عملکرد هر روش SSL را در SVHN با تعداد متغیر برچسب‌ها از 250 تا 4000 ارزیابی می‌کنیم. همانطور که روش استاندارد است، ابتدا تنظیماتی را در نظر می‌گیریم که مجموعه آموزشی 73257 نمونه‌ای به داده‌های برچسب‌دار و بدون برچسب تقسیم می‌شود. نتایج در شکل 3 نشان داده شده است. ما از λU = 250 استفاده کردیم. در اینجا نیز مدل‌ها در 5 تقسیم برای هر تعداد نقطه برچسب‌دار، که هر کدام دارای یک دانه تصادفی متفاوت بودند، ارزیابی شدند. متوجه شدیم که عملکرد MixMatch در تمام مقادیر داده‌های برچسب‌دار نسبتاً ثابت (و بهتر از همه روش‌های دیگر) است. به طور شگفت‌انگیزی، پس از تنظیم بیشتر، توانستیم عملکرد بسیار خوبی از معلم میانگین [44] به دست آوریم، اگرچه نرخ خطای آن به طور مداوم کمی بالاتر از MixMatch بود.

توجه داشته باشید که SVHN دارای دو مجموعه آموزشی است: train و extra. در یادگیری کاملاً نظارت شده، هر دو مجموعه به هم متصل می‌شوند تا مجموعه آموزشی کامل (604388 نمونه) را تشکیل دهند. در SSL، به دلایل تاریخی، مجموعه extra کنار گذاشته شد و فقط train استفاده شد (73257 نمونه). ما استدلال می‌کنیم که استفاده از هر دو train و extra برای داده‌های بدون برچسب جالب‌تر است زیرا نسبت بالاتری از نمونه‌های بدون برچسب نسبت به نمونه‌های برچسب‌دار را نشان می‌دهد. ما نرخ‌های خطا را برای هر دو SVHN و SVHN+Extra در جدول 3 گزارش می‌کنیم. برای SVHN+Extra از α = 0.25؛ λU = 250 و کاهش وزن پایین‌تر 0.000002 به دلیل مقدار بیشتر داده‌های موجود استفاده کردیم. متوجه شدیم که در هر دو مجموعه آموزشی، MixMatch تقریباً بلافاصله با عملکرد کاملاً نظارت شده در همان مجموعه آموزشی مطابقت دارد - برای مثال، MixMatch با تنها 250 برچسب در SVHN+Extra به نرخ خطای 2.22 درصد در مقایسه با عملکرد کاملاً نظارت شده 1.71 درصد می‌رسد. جالب اینجاست که در SVHN+Extra، MixMatch از آموزش کاملاً نظارت شده در SVHN بدون extra (خطای 2.59 درصد) برای هر مقدار داده برچسب‌دار در نظر گرفته شده بهتر عمل کرد. برای تأکید بر اهمیت این موضوع، سناریوی زیر را در نظر بگیرید: شما 73257 نمونه از SVHN با 250 نمونه برچسب‌دار دارید و یک انتخاب به شما داده می‌شود: می‌توانید 8 برابر داده‌های بدون برچسب بیشتری به دست آورید و از MixMatch استفاده کنید یا 293 برابر داده‌های برچسب‌دار بیشتری به دست آورید و از یادگیری کاملاً نظارت شده استفاده کنید. نتایج ما نشان می‌دهد که به دست آوردن داده‌های بدون برچسب اضافی و استفاده از MixMatch مؤثرتر است، که به طور مناسبی احتمالاً بسیار ارزان‌تر از به دست آوردن 293 برابر برچسب بیشتر است.

‏**STL-10** STL-10 شامل 5000 نمونه آموزشی است که برای استفاده با 10 پوشه از پیش تعریف شده (ما فقط 5 تای اول را استفاده می‌کنیم) با 1000 نمونه در هر کدام در نظر گرفته شده است. با این حال، برخی از کارهای قبلی بر روی تمام 5000 نمونه آموزش می‌دهند. بنابراین ما در هر دو تنظیمات آزمایشی مقایسه می‌کنیم. با 1000 نمونه، MixMatch هم از پیشرفته‌ترین روش برای 1000 نمونه و هم از پیشرفته‌ترین روش با استفاده از تمام 5000 نمونه برچسب‌دار پیشی می‌گیرد. توجه داشته باشید که هیچ یک از خطوط پایه در جدول 2 از همان تنظیمات آزمایشی (یعنی مدل) استفاده نمی‌کنند، بنابراین مقایسه مستقیم نتایج دشوار است؛ با این حال، از آنجایی که MixMatch کمترین خطا را با ضریب دو به دست می‌آورد، این را به عنوان یک رأی اعتماد به روش خود در نظر می‌گیریم. ما از λU = 50 استفاده کردیم.

#### مطالعه ابلیشن

از آنجایی که MixMatch مکانیسم‌های مختلف یادگیری نیمه‌نظارتی را ترکیب می‌کند، اشتراکات زیادی با روش‌های موجود در ادبیات دارد. در نتیجه، اثر حذف یا اضافه کردن اجزا را بررسی می‌کنیم تا بینش بیشتری در مورد عواملی که MixMatch را پربازده می‌کنند، ارائه دهیم. به طور خاص، اثر موارد زیر را اندازه‌گیری می‌کنیم:


![[assets/c13.png]](/assets/c13.png)

- استفاده از توزیع کلاس میانگین در K تقویت یا استفاده از توزیع کلاس برای یک تقویت منفرد (یعنی تنظیم K = 1)
- حذف تیز کردن دما (یعنی تنظیم T = 1)
- استفاده از میانگین متحرک نمایی (EMA) پارامترهای مدل هنگام تولید برچسب‌های حدس زده شده، همانطور که توسط معلم میانگین [44] انجام می‌شود.
- انجام MixUp فقط بین نمونه‌های برچسب‌دار، فقط نمونه‌های بدون برچسب، و بدون ترکیب بین نمونه‌های برچسب‌دار و بدون برچسب.
- استفاده از آموزش سازگاری درون‌یابی [45]، که می‌تواند به عنوان یک حالت خاص از این مطالعه ابلیشن در نظر گرفته شود که در آن فقط mixup بدون برچسب استفاده می‌شود، هیچ تیز کردنی اعمال نمی‌شود و پارامترهای EMA برای حدس زدن برچسب استفاده می‌شوند.

ما ابلیشن را روی CIFAR-10 با 250 و 4000 برچسب انجام دادیم؛ نتایج در جدول 4 نشان داده شده است. متوجه شدیم که هر جزء به عملکرد MixMatch کمک می‌کند، با چشمگیرترین تفاوت‌ها در تنظیمات 250 برچسب. علی‌رغم اثربخشی معلم میانگین در SVHN (شکل 3)، متوجه شدیم که استفاده از EMA مشابه مقادیر پارامتر کمی به عملکرد MixMatch آسیب می‌زند.

### یادگیری حفظ حریم خصوصی و تعمیم

یادگیری با حفظ حریم خصوصی به ما امکان می‌دهد توانایی رویکرد خود را در تعمیم اندازه‌گیری کنیم. در واقع، محافظت از حریم خصوصی داده‌های آموزشی به اثبات اینکه مدل بیش‌برازش نمی‌کند، منجر می‌شود: یک الگوریتم یادگیری زمانی گفته می‌شود که به صورت دیفرانسیلی خصوصی باشد (پذیرفته‌شده‌ترین تعریف فنی حریم خصوصی) اگر اضافه کردن، اصلاح یا حذف هر یک از نمونه‌های آموزشی آن تضمین شود که منجر به تفاوت آماری قابل توجهی در پارامترهای مدل یاد گرفته شده نمی‌شود [13]. به همین دلیل، یادگیری با حریم خصوصی دیفرانسیلی، در عمل، نوعی منظم‌سازی است [33]. هر دسترسی به داده‌های آموزشی، یک نشت بالقوه حریم خصوصی را تشکیل می‌دهد که به صورت جفت ورودی و برچسب آن کدگذاری می‌شود. از این رو، رویکردهای یادگیری عمیق از داده‌های آموزشی خصوصی، مانند DP-SGD [1] و PATE [36]، از دسترسی به کمترین نقاط آموزشی خصوصی برچسب‌دار ممکن هنگام محاسبه به‌روزرسانی‌های پارامترهای مدل سود می‌برند. یادگیری نیمه‌نظارتی یک تناسب طبیعی برای این تنظیمات است. ما از چارچوب PATE برای یادگیری با حریم خصوصی استفاده می‌کنیم. یک دانش‌آموز به صورت نیمه‌نظارتی از داده‌های بدون برچسب عمومی آموزش داده می‌شود، که بخشی از آن توسط مجموعه‌ای از معلمان با دسترسی به داده‌های آموزشی برچسب‌دار خصوصی برچسب‌گذاری می‌شود. هر چه دانش‌آموز برای رسیدن به دقت ثابت به برچسب‌های کمتری نیاز داشته باشد، ضمانت حریم خصوصی که ارائه می‌دهد قوی‌تر است. معلمان از یک مکانیسم رأی‌گیری پرنویز برای پاسخ دادن به پرسش‌های برچسب از دانش‌آموز استفاده می‌کنند و ممکن است در صورت عدم دستیابی به اجماع به اندازه کافی قوی، برچسب ارائه نکنند. به همین دلیل، اگر MixMatch عملکرد PATE را بهبود بخشد، تعمیم بهبود یافته MixMatch از نمونه‌های متعارف کم هر کلاس را نیز نشان می‌دهد. ما توازن دقت-حریم خصوصی به دست آمده توسط MixMatch را با یک خط پایه VAT [31] در SVHN مقایسه می‌کنیم. VAT به پیشرفته‌ترین دقت آزمون 91.6 درصد برای از دست دادن حریم خصوصی " = 4.96 [37] دست یافت. از آنجایی که MixMatch با نقاط برچسب‌دار کم عملکرد خوبی دارد، می‌تواند به دقت آزمون 95.21 ± 0.17 درصد برای از دست دادن حریم خصوصی بسیار کمتر " = 0.97 دست یابد. از آنجایی که e" برای اندازه‌گیری درجه حریم خصوصی استفاده می‌شود، بهبود تقریباً e4 ≈ 55 برابر است، یک بهبود قابل توجه. از دست دادن حریم خصوصی " کمتر از 1 مربوط به ضمانت حریم خصوصی بسیار قوی‌تر است. توجه داشته باشید که در تنظیمات آموزشی خصوصی، مدل دانش‌آموز فقط از 10000 نمونه کل استفاده می‌کند.

5. نتیجه‌گیری

ما MixMatch را معرفی کردیم، یک روش یادگیری نیمه‌نظارتی که ایده‌ها و اجزای پارادایم‌های غالب فعلی برای SSL را ترکیب می‌کند. از طریق آزمایش‌های گسترده در یادگیری نیمه‌نظارتی و حفظ حریم خصوصی، متوجه شدیم که MixMatch در مقایسه با روش‌های دیگر در تمام تنظیمات مورد مطالعه، عملکرد به طور قابل توجهی بهبود یافته‌ای را نشان می‌دهد، اغلب با ضریب دو یا بیشتر کاهش در نرخ خطا. در کارهای آینده، ما علاقه‌مند به گنجاندن ایده‌های اضافی از ادبیات یادگیری نیمه‌نظارتی در روش‌های ترکیبی و ادامه بررسی اینکه کدام اجزا منجر به الگوریتم‌های مؤثر می‌شوند، هستیم. جدا از این، بیشتر کارهای مدرن در مورد الگوریتم‌های یادگیری نیمه‌نظارتی در بنچمارک‌های تصویر ارزیابی می‌شوند؛ ما علاقه‌مند به بررسی اثربخشی MixMatch در حوزه‌های دیگر هستیم.


### نکته: بعد مراجعه ادامه دارد ولی ترجمه نکردم چون ساده بود
