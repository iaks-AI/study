
[Machine Learning-based Damage Assessment for Disaster Relief](https://research.google/blog/machine-learning-based-damage-assessment-for-disaster-relief/)

بلایای طبیعی مانند زلزله، گردباد و سیل بر مناطق وسیع و میلیون‌ها نفر تأثیر می‌گذارند، اما واکنش به چنین بلایایی یک چالش لجستیکی عظیم است. پاسخ‌دهندگان به بحران، از جمله دولت‌ها، سازمان‌های غیردولتی و سازمان‌های سازمان ملل متحد، برای برنامه‌ریزی بهترین نحوه تخصیص منابع محدود، به دسترسی سریع به ارزیابی‌های جامع و دقیق در پی بلایا نیاز دارند. بدین منظور، تصاویر ماهواره‌ای با وضوح بسیار بالا (VHR)، با رزولوشن تا 0.3 متر، به طور فزاینده‌ای به یک ابزار مهم برای پاسخ به بحران تبدیل شده است که به پاسخ‌دهندگان اطلاعات بصری بی‌سابقه‌ای در مورد تغییرات زمین، زیرساخت‌ها و جمعیت‌ها در اثر بلایا می‌دهد.

با این حال، هنوز نیاز به کار دستی شدید برای استخراج اطلاعات مرتبط با عملیات - ساختمان‌های فروریخته، ترک‌های پل، جاهایی که مردم سرپناه موقت برپا کرده‌اند - از تصاویر خام ماهواره‌ای وجود دارد. به عنوان مثال، برای زلزله هائیتی در سال 2010، تحلیلگران بیش از 90,000 ساختمان را در منطقه پورت-اوپرنس به تنهایی به صورت دستی بررسی کردند و خسارات وارده به هر کدام را در یک مقیاس 5 نقطه‌ای رتبه‌بندی کردند. بسیاری از این تحلیل‌های دستی چندین هفته طول می‌کشد تا توسط تیم‌های متخصص انجام شود، در حالی که آنها در عرض 48-72 ساعت بعد از بلایا، زمانی که تصمیمات فوری‌ترین گرفته می‌شود، مورد نیاز هستند.

برای کمک به کاهش تأثیر چنین بلایایی، ما "تشخیص آسیب ساختمان در تصاویر ماهواره‌ای با استفاده از شبکه‌های عصبی کانولوشنال" را ارائه می‌کنیم که رویکرد یادگیری ماشین (ML) را برای پردازش خودکار داده‌های ماهواره‌ای به منظور تولید ارزیابی‌های آسیب ساختمان شرح می‌دهد. این کار که در همکاری با شتاب‌دهنده نوآوری برنامه جهانی غذا سازمان ملل متحد (WFP) توسعه یافته است، ما معتقدیم که پتانسیل کاهش چشمگیر زمان و تلاش مورد نیاز برای کارگران بحران برای تولید گزارش‌های ارزیابی خسارت را دارد. به نوبه خود، این امر زمان چرخش لازم برای ارائه کمک‌های به موقع بلایا به مناطق آسیب دیده شدیدتر را کاهش می‌دهد، در حالی که پوشش کلی چنین خدمات بحرانی را افزایش می‌دهد.

رویکرد
فرآیند ارزیابی خودکار آسیب به دو مرحله تقسیم می‌شود: تشخیص ساختمان و طبقه‌بندی آسیب. در مرحله تشخیص ساختمان، رویکرد ما از یک مدل تشخیص شیء برای ترسیم کادرهای محصور کننده در اطراف هر ساختمان در تصویر استفاده می‌کند. سپس ما تصاویر قبل و بعد از بلایا را متمرکز بر هر ساختمان تشخیص داده شده استخراج می‌کنیم و از یک مدل طبقه‌بندی برای تعیین آسیب یا عدم آسیب ساختمان استفاده می‌کنیم.

![[assets/a1.png]](/assets/a1.png)

**مدل طبقه‌بندی شامل یک شبکه‌ی عصبی کانولوشنی است که ورودی آن دو تصویر RGB با ابعاد ۱۶۱ در ۱۶۱ پیکسل است. این تصاویر معادل یک ناحیه‌ی زمینی به ابعاد ۵۰ متر در ۵۰ متر هستند که در مرکز آن، ساختمان موردنظر قرار دارد. یکی از این تصاویر مربوط به قبل از وقوع فاجعه است و تصویر دیگر پس از وقوع فاجعه ثبت شده است. مدل با تحلیل تفاوت‌های بین این دو تصویر، یک امتیاز بین ۰.۰ تا ۱.۰ تولید می‌کند، به طوری که مقدار ۰.۰ نشان‌دهنده‌ی عدم آسیب‌دیدگی ساختمان و مقدار ۱.۰ نشان‌دهنده‌ی آسیب‌دیدگی کامل آن است.**  

از آنجایی که تصاویر قبل و بعد از فاجعه در تاریخ‌های مختلف، ساعات متفاوت از شبانه‌روز، و در برخی موارد حتی توسط ماهواره‌های مختلف گرفته شده‌اند، ممکن است چالش‌های متعددی ایجاد شود. برای مثال، روشنایی، کنتراست، میزان اشباع رنگ و شرایط نوری تصاویر ممکن است به‌شدت با یکدیگر تفاوت داشته باشند و همچنین ممکن است پیکسل‌های تصویر به‌درستی هم‌راستا نباشند.  

برای اصلاح تفاوت‌های رنگ و روشنایی، از **همسان‌سازی هیستوگرام** (Histogram Equalization) برای نرمال‌سازی رنگ‌های تصاویر قبل و بعد از فاجعه استفاده می‌کنیم. همچنین، برای افزایش مقاومت مدل در برابر تفاوت‌های جزئی رنگی، در طول فرآیند آموزش از تکنیک‌های استاندارد **افزایش داده‌ها** (Data Augmentation) مانند تغییر تصادفی کنتراست و اشباع رنگ تصاویر استفاده می‌کنیم.  

### **داده‌های آموزشی**  
یکی از چالش‌های اصلی این کار، **جمع‌آوری مجموعه داده‌های آموزشی** است. دسترسی به داده‌ها در این کاربرد ذاتاً محدود است، زیرا تنها تعداد کمی از بلایای طبیعی دارای تصاویر ماهواره‌ای با وضوح بالا هستند و تعداد کمتری از آن‌ها دارای ارزیابی‌های خسارت از پیش موجود می‌باشند.  

برای برچسب‌گذاری (Labels)، از ارزیابی‌های خسارتی که به‌صورت دستی توسط سازمان‌های بشردوستانه‌ی فعال در این حوزه، مانند **UNOSAT** و **REACH**، تهیه شده و به‌صورت عمومی در دسترس هستند، استفاده می‌کنیم. ما تصاویر ماهواره‌ای اصلی که این ارزیابی‌های دستی بر روی آن‌ها انجام شده است را دریافت کرده و سپس با استفاده از **Google Earth Engine**، برچسب‌های ارزیابی خسارت را به‌صورت مکانی با تصاویر ماهواره‌ای تطبیق می‌دهیم تا نمونه‌های نهایی آموزشی را تولید کنیم.  

تمام تصاویری که برای آموزش مدل استفاده شده‌اند، از منابع تجاری در دسترس تهیه شده‌اند.

![[assets/a2.png]](/assets/a2.png)

|   |
|---|
|Examples of individual image patches that capture before and after images of damaged and undamaged buildings from different disasters.|

### **نتایج**  

ما این فناوری را برای **سه زلزله‌ی بزرگ گذشته** ارزیابی کردیم: **زلزله‌ی سال ۲۰۱۰ در هائیتی** (با بزرگی ۷.۰ ریشتر)، **زلزله‌ی سال ۲۰۱۷ در مکزیکوسیتی** (با بزرگی ۷.۱ ریشتر)، و **مجموعه زلزله‌های سال ۲۰۱۸ در اندونزی** (با بزرگی بین ۵.۹ تا ۷.۵ ریشتر).  

برای هر یک از این رویدادها، مدل را با داده‌های مربوط به ساختمان‌های یک بخش از منطقه‌ی آسیب‌دیده آموزش دادیم و سپس آن را بر روی ساختمان‌های بخش دیگری از همان منطقه آزمایش کردیم. برای ارزیابی عملکرد مدل، از **ارزیابی‌های خسارت انجام‌شده توسط کارشناسان انسانی در سازمان‌های UNOSAT و REACH** به عنوان **مبنای حقیقت (Ground Truth)** استفاده کردیم.  

کیفیت مدل را با استفاده از **دو معیار** اندازه‌گیری کردیم:  
1. **دقت واقعی** (مقایسه‌ی نتایج مدل با ارزیابی‌های کارشناسان)  
2. **مساحت زیر منحنی مشخصه عملکرد گیرنده (AUROC)**، که میزان تعادل بین نرخ تشخیص درست (True Positive) و نرخ تشخیص نادرست (False Positive) را نشان می‌دهد. این معیار معمولاً در شرایطی استفاده می‌شود که تعداد نمونه‌های مثبت و منفی در مجموعه داده‌ی آزمایشی نامتوازن باشد.  

مقدار **AUROC برابر 0.5** نشان می‌دهد که پیش‌بینی‌های مدل **تصادفی** هستند، در حالی که مقدار **1.0** به این معناست که مدل **کاملاً دقیق** عمل می‌کند.  

بر اساس بازخوردی که از نیروهای امدادرسان دریافت کردیم، **حداقل دقت موردنیاز برای تصمیم‌گیری‌های کلان در ۷۲ ساعت نخست پس از وقوع فاجعه، ۷۰٪ است.**

![[assets/a3.png]](/assets/a3.png)

![[assets/a4.png]](/assets/a4.png)

### **کارهای آینده**  

در حالی که مدل کنونی **عملکرد قابل قبولی** دارد زمانی که بر روی ساختمان‌های **یک منطقه‌ی خاص** (مثلاً یک شهر یا کشور مشخص) **آموزش داده شده و آزمایش شود**، هدف نهایی این است که مدلی داشته باشیم که بتواند **به‌طور دقیق خسارت ساختمان‌ها را در بلایایی که در هر نقطه‌ای از جهان رخ می‌دهند، ارزیابی کند**، نه فقط در مناطقی که شبیه به داده‌های آموزشی مدل هستند.  

این امر **چالشی مهم** محسوب می‌شود، زیرا **تنوع داده‌های آموزشی** که از بلایای گذشته در دسترس داریم، ذاتاً محدود است و تنها به **تعداد کمی از رویدادهایی که در مکان‌های جغرافیایی خاص رخ داده‌اند**، مربوط می‌شود. بنابراین، **تعمیم مدل** برای بلایای آینده که احتمالاً در **مکان‌های جدیدی رخ خواهند داد**، همچنان یکی از چالش‌های اصلی ماست و **تمرکز تحقیقات و توسعه‌ی آینده‌ی این پروژه خواهد بود**.  

چشم‌انداز ما توسعه‌ی **یک سیستم تعاملی** است که بتواند توسط **تحلیلگران متخصص آموزش داده شود، اعتبارسنجی گردد و در شرایط واقعی به کار گرفته شود**، به طوری که تصمیمات حیاتی برای **توزیع کمک‌ها** همواره توسط امدادرسانان باتجربه **تأیید شوند**.  

**امید ما این است که این فناوری بتواند به جوامع آسیب‌دیده کمک کند تا در بحرانی‌ترین شرایط، کمک‌های موردنیاز خود را در کوتاه‌ترین زمان ممکن دریافت کنند.**  

---

### **تقدیر و تشکر**  

این مقاله حاصل کار **همکاران ما، ونهان لو (Wenhan Lu) و زبو لی (Zebo Li)** است. همچنین، از **ماولین زو (Maolin Zuo)** به خاطر مشارکت‌های ارزشمندش در این پروژه قدردانی می‌کنیم.  

برای حل این مشکل، ما همکاری بسیار **موفقی** با **مرکز نوآوری برنامه جهانی غذای سازمان ملل (WFP Innovation Accelerator)** داشته‌ایم—سازمانی که مأموریت آن **شناسایی، تأمین مالی و حمایت از استارتاپ‌ها و پروژه‌های نوآورانه برای مقابله با بحران گرسنگی در جهان است.**